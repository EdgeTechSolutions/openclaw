# 2026-02-28

## Gmail Triage — 05:00 CET
- **13 emails** processed | 5 archived | 2 unsubscribed | 1 invoice uploaded
- gmail_triage:19ca11416adfd4c2 — Google (Other) "Google Payments: Payment method updated for MineIT" — Google Payments (kept)
- gmail_triage:19ca10984ad4942f — Invoices "Your Invoice from Mistral AI SAS #MSTRL-API-791047-001" — Mistral AI (kept, PDF uploaded to Drive/2026-02, file ID 1Tumd5SZRVekCHERVh6NgaSEJ3rVmBhYK)
- gmail_triage:19ca0e206bf1eeed — Trading 212 "Login from a new device" — Trading 212 (kept)
- gmail_triage:19ca08892945c2de — Google Workspace "Review and manage your conversation retention settings for Gemini" — Google Workspace Team (kept)
- gmail_triage:19ca06a9c0a0d25c — LinkedIn "You have 1 new invitation" — LinkedIn (archived)
- gmail_triage:19c9fe7bd749ad68 — LinkedIn "Chief Technology Officer: Vandri AI and AI BISTRO" — LinkedIn (archived)
- gmail_triage:19c9f1caae6c881d — Personal/Work "FW: Poročilo o pregledu ODT Topniška" — Tadej Ježek (kept)
- gmail_triage:19c9f0c085ba02fc — LinkedIn "I want to connect" — Aleksander Šinigoj (archived)
- gmail_triage:19c9e886726ed2c2 — Personal/Work "Item shared: Rojstni list_Andrej.pdf" — Jasna Grzelj via Google Drive (kept)
- gmail_triage:19c9e667a54a7294 — Promotions "Osebna priporočila za vas" — Lumories (unsubscribed ✓, archived)
- gmail_triage:19c9e6156b120a01 — Qogita "How many hours per month?" — Pranav Hooda (kept)
- gmail_triage:19c9e48b376016f7 — Promotions "Obvestilo o posodobljenih Pravilih in pogojih uporabe" — Moje Delo (unsubscribed ✓, archived)
- gmail_triage:19c9dec61cf2b3ad — Google (Other) "Portal SPOT: Obvestilo o spremembi statusa — REŠENO — POZITIVNO" — gov.si (kept)
- Categories: Personal/Work (2), Invoices (1), Trading 212 (1), Google Workspace (1), Google Other (2), LinkedIn (3), Promotions (2), Qogita (1)

## Evening — Hugging Face Skill Built (~22:00 CET)

Created new skill at `/workspace/skills/huggingface/` with 3 Python scripts (stdlib only, no pip deps):

- `scripts/search_models.py` — search HF Hub by query/task/sort; sort options: `downloads`, `likes`, `lastModified`, `createdAt`; `--new` alias for lastModified; `--min-downloads` filter
- `scripts/leaderboard.py` — Open LLM Leaderboard v2 (`open-llm-leaderboard/contents`); filters: `--max-params`, `--min-params`, `--no-moe`, `--no-merged`; `--scan N` controls rows scanned (default 500); `--benchmarks` shows IFEval/BBH/MATH/GPQA/MUSR/MMLU-PRO
- `scripts/model_info.py` — detailed metadata for a single model (task, license, languages, base model, eval results, GGUF/safetensor shards)
- All scripts support `HF_TOKEN` env var for higher rate limits / gated model access
- `trending` is NOT a valid HF API sort value (returns 400) — removed it

### Lesson learned
- **Always verify data before writing to Confluence** — first GLM-5 page had 10× wrong file sizes because shard sizes were estimated (~4.5 GB) instead of fetched from HF LFS metadata (`blobs=true` param). Fix required a second update. Check sources first, write once.

### GLM-5 Research
- GLM-5 is a **744B total / 40B active MoE model** by Z.ai (zai-org)
- `unsloth/GLM-5-GGUF` Q4_K_M = ~220GB (11 shards); BF16 = ~148GB (33 shards)
- `Maklei/GLM-5-pruned-Q4_K_M-GGUF` = single file, **218GB** (pruning barely reduces size)
- Hardware to run Q4_K_M: **4× A100 80GB** or **3-4× H100 80GB** (~$8–12/hr cloud rental)
- Buying 4× H100: ~$140k–$160k GPUs only; full server $200k–$300k
- Practical recommendation: use Z.ai API or OpenRouter for hosted inference
